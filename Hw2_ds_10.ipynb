{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD, SVDpp, NMF\n",
    "from surprise.model_selection import cross_validate, GridSearchCV\n",
    "\n",
    "# Download data\n",
    "ratings = pd.read_csv('/mnt/data/ratings.csv')\n",
    "\n",
    "# Convert data to a format supported by the Surprise library\n",
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Selection of the best parameters for SVD\n",
    "param_grid = {\n",
    "    'n_factors': [20, 50, 100],\n",
    "    'lr_all': [0.002, 0.005, 0.01],\n",
    "    'reg_all': [0.02, 0.1, 0.4]\n",
    "}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=5)\n",
    "gs.fit(data)\n",
    "\n",
    "print(\"Найкращі параметри для SVD:\", gs.best_params['rmse'])\n",
    "\n",
    "# Model building and evaluation\n",
    "algorithms = {\n",
    "    'SVD': SVD(n_factors=gs.best_params['rmse']['n_factors'],\n",
    "               lr_all=gs.best_params['rmse']['lr_all'],\n",
    "               reg_all=gs.best_params['rmse']['reg_all']),\n",
    "    'SVD++': SVDpp(),\n",
    "    'NMF': NMF()\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, algo in algorithms.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    results[name] = cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "\n",
    "# Comparing the results\n",
    "for name, result in results.items():\n",
    "    print(f\"\\n{name} performance:\")\n",
    "    for metric in ['test_rmse', 'test_mae']:\n",
    "        print(f\"{metric}: {result[metric].mean():.4f} ± {result[metric].std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Download data\n",
    "ratings = pd.read_csv('/mnt/data/ratings.csv')\n",
    "\n",
    "# Options\n",
    "num_users = ratings['userId'].nunique()\n",
    "num_movies = ratings['movieId'].nunique()\n",
    "latent_factors = 10  # Кількість латентних факторів\n",
    "learning_rate = 0.01\n",
    "regularization = 0.1\n",
    "epochs = 20\n",
    "\n",
    "# Initialize factor matrices\n",
    "user_factors = np.random.normal(scale=1.0/latent_factors, size=(num_users, latent_factors))\n",
    "movie_factors = np.random.normal(scale=1.0/latent_factors, size=(num_movies, latent_factors))\n",
    "\n",
    "# Splitting data into training and test samples\n",
    "train_data, test_data = train_test_split(ratings, test_size=0.2)\n",
    "\n",
    "# Mapping IDs to indexes\n",
    "user_id_map = {id: idx for idx, id in enumerate(ratings['userId'].unique())}\n",
    "movie_id_map = {id: idx for idx, id in enumerate(ratings['movieId'].unique())}\n",
    "\n",
    "train_data['user_index'] = train_data['userId'].map(user_id_map)\n",
    "train_data['movie_index'] = train_data['movieId'].map(movie_id_map)\n",
    "test_data['user_index'] = test_data['userId'].map(user_id_map)\n",
    "test_data['movie_index'] = test_data['movieId'].map(movie_id_map)\n",
    "\n",
    "# Gradient descent\n",
    "for epoch in range(epochs):\n",
    "    for _, row in train_data.iterrows():\n",
    "        user_idx = int(row['user_index'])\n",
    "        movie_idx = int(row['movie_index'])\n",
    "        rating = row['rating']\n",
    "\n",
    "       # Forecasted rating\n",
    "        pred_rating = np.dot(user_factors[user_idx], movie_factors[movie_idx])\n",
    "\n",
    "        # Error\n",
    "        error = rating - pred_rating\n",
    "\n",
    "       # Update factors\n",
    "        user_factors[user_idx] += learning_rate * (error * movie_factors[movie_idx] - regularization * user_factors[user_idx])\n",
    "        movie_factors[movie_idx] += learning_rate * (error * user_factors[user_idx] - regularization * movie_factors[movie_idx])\n",
    "    \n",
    "    # Calculating the RMSE on a training set\n",
    "    train_rmse = np.sqrt(np.mean([\n",
    "        (row['rating'] - np.dot(user_factors[int(row['user_index'])], movie_factors[int(row['movie_index'])])) ** 2\n",
    "        for _, row in train_data.iterrows()\n",
    "    ]))\n",
    "    \n",
    "  # Calculate RMSE on the test sample\n",
    "    test_rmse = np.sqrt(np.mean([\n",
    "        (row['rating'] - np.dot(user_factors[int(row['user_index'])], movie_factors[int(row['movie_index'])])) ** 2\n",
    "        for _, row in test_data.iterrows()\n",
    "    ]))\n",
    "    \n",
    "    print(f'Epoch {epoch + 1}: Train RMSE = {train_rmse:.4f}, Test RMSE = {test_rmse:.4f}')\n",
    "\n",
    "# Final factors\n",
    "user_factors_final = user_factors\n",
    "movie_factors_final = movie_factors\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
